# Image Captioning (IC) dataset
The dataset has been designed for the task of recognizing whether a caption is a good (positive) or a bad (negative) caption for an image. The dataset has been generated by exploiting both the MSCOCO [1] dataset. In order to obtain this dataset, for each image contained in the training set/development set of MSCOCO 2014, we sampled:
- two positive caption from MSCOCO;
- one negative caption from MSCOCO such that it corresponds to an image with a number of categories in common with the actual image which is less or equal than two.

The script implementing the dataset generation procedure has been parametrized to allow to sample the desired number of positive and negative captions for each image.

The dataset generated from the development set has been split into test and development sets with a ratio of 50/50 such that each of these two sets contains both the positive and negative captions for each image.

[1] Lin, Tsung-Yi, et al. "Microsoft coco: Common objects in context." European conference on computer vision. Springer, Cham, 2014.
